{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ac05e1-62a6-4898-ae7c-9c18311da5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c9395b5-10b4-4a53-86e2-c5a997088b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_img = cv2.imread('GT.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "127ae7f4-bd05-475c-9568-3f04beb5f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = os.listdir('/media/CenterCameraModel/Annos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c42f71f8-73e2-455a-a940-7bdd49f52d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_point(point, pivot, theta_degrees):\n",
    "    theta_radians = math.radians(theta_degrees)\n",
    "    translated_point = (point[0] - pivot[0], point[1] - pivot[1])\n",
    "    rotated_x = translated_point[0] * math.cos(theta_radians) - translated_point[1] * math.sin(theta_radians)\n",
    "    rotated_y = translated_point[0] * math.sin(theta_radians) + translated_point[1] * math.cos(theta_radians)\n",
    "    new_point = (rotated_x + pivot[0], rotated_y + pivot[1])\n",
    "    \n",
    "    return new_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22726a92-82d8-40d2-b6d5-638332fc0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair(line):\n",
    "    pattern = r\"\\((-?\\d*\\.?\\d+),\\s*(-?\\d*\\.?\\d+)\\)\"\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        first_number = match.group(1)\n",
    "        second_number = match.group(2)\n",
    "        return [float(first_number), float(second_number)]\n",
    "    else:\n",
    "        print(\"No match found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aff191a0-52b1-4724-bc55-8e28d3f076ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample():\n",
    "    indx = np.random.randint(0, len(data_set))\n",
    "    target_file = data_set[indx][:-4]\n",
    "    # target_file = 'PSG VS Man City 2nd-000367.jpg'\n",
    "    # print(target_file)\n",
    "    with open('Annos/{}.txt'.format(target_file), 'r') as file:\n",
    "        # Read the entire file content\n",
    "        file_content = file.read()\n",
    "    \n",
    "    trap_points = {}\n",
    "    trap_points['top_left'] = get_pair(file_content.split('\\n')[1])\n",
    "    trap_points['top_right'] = get_pair(file_content.split('\\n')[2])\n",
    "    trap_points['bottom_right'] = get_pair(file_content.split('\\n')[3])\n",
    "    trap_points['bottom_left'] = get_pair(file_content.split('\\n')[4])\n",
    "    center_x = (trap_points['top_left'][0] + trap_points['top_right'][0] + trap_points['bottom_right'][0] + trap_points['bottom_left'][0])/4\n",
    "    center_y = (trap_points['top_left'][1] + trap_points['top_right'][1] + trap_points['bottom_right'][1] + trap_points['bottom_left'][1])/4\n",
    "    trap_points['center'] = [center_x, center_y]\n",
    "    \n",
    "    rect_points = {}\n",
    "    rect_points['top_left'] = get_pair(file_content.split('\\n')[6])\n",
    "    rect_points['top_right'] = get_pair(file_content.split('\\n')[8])\n",
    "    rect_points['bottom_right'] = get_pair(file_content.split('\\n')[7])\n",
    "    rect_points['bottom_left'] = get_pair(file_content.split('\\n')[9])\n",
    "    center_x = (rect_points['top_left'][0] + rect_points['top_right'][0] + rect_points['bottom_right'][0] + rect_points['bottom_left'][0])/4\n",
    "    center_y = (rect_points['top_left'][1] + rect_points['top_right'][1] + rect_points['bottom_right'][1] + rect_points['bottom_left'][1])/4\n",
    "    rect_points['center'] = [center_x, center_y]\n",
    "    \n",
    "    rotations = {}\n",
    "    rotations['trap'] = float(file_content.split('\\n')[11])\n",
    "    rotations['rect'] = float(file_content.split('\\n')[13])\n",
    "    \n",
    "    trap_points['top_left'] = rotate_point(trap_points['top_left'], trap_points['center'], rotations['trap'])\n",
    "    trap_points['top_right'] = rotate_point(trap_points['top_right'], trap_points['center'], rotations['trap'])\n",
    "    trap_points['bottom_right'] = rotate_point(trap_points['bottom_right'], trap_points['center'], rotations['trap'])\n",
    "    trap_points['bottom_left'] = rotate_point(trap_points['bottom_left'], trap_points['center'], rotations['trap'])\n",
    "\n",
    "    rect_points['top_left'] = rotate_point(rect_points['top_left'], rect_points['center'], rotations['rect'])\n",
    "    rect_points['top_right'] = rotate_point(rect_points['top_right'], rect_points['center'], rotations['rect'])\n",
    "    rect_points['bottom_right'] = rotate_point(rect_points['bottom_right'], rect_points['center'], rotations['rect'])\n",
    "    rect_points['bottom_left'] = rotate_point(rect_points['bottom_left'], rect_points['center'], rotations['rect'])\n",
    "    \n",
    "    src_points = np.array([trap_points['top_left'], trap_points['top_right'], trap_points['bottom_right'], trap_points['bottom_left']], dtype=np.float32)\n",
    "    dst_points = np.array([rect_points['top_left'], rect_points['top_right'], rect_points['bottom_right'], rect_points['bottom_left']], dtype=np.float32)\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    \n",
    "    y = M.reshape(9)\n",
    "    # print(\"GT/{}png\".format(target_file[:-3]))\n",
    "    X = cv2.imread(\"GT/{}png\".format(target_file[:-3]), 0)\n",
    "    X[X> 10] = 255\n",
    "    X[X<= 10] = 0\n",
    "    cv2.imwrite('t.jpg', X)\n",
    "    X = X/255.0\n",
    "    \n",
    "    y[0] = y[0]*10\n",
    "    y[1] = y[1]*10\n",
    "    y[3] = y[3]*10\n",
    "    y[4] = y[4]*10\n",
    "    \n",
    "    y[2] = y[2]/X.shape[0]\n",
    "    y[5] = y[5]/X.shape[1]\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    \n",
    "    return X, y, \"imgs/{}jpg\".format(target_file[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0def2dd7-92d1-4bc8-ae46-c9468009d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1200):\n",
    "    _, y, img_file = get_sample()\n",
    "    img = cv2.imread(img_file)\n",
    "    y[2] = y[2]*img.shape[0]\n",
    "    y[5] = y[5]*img.shape[1]\n",
    "    \n",
    "    M = y.reshape((3,3))\n",
    "    warped_image = cv2.warpPerspective(img, M, (GT_img.shape[1], GT_img.shape[0]))\n",
    "    cv2.imwrite('val/' + img_file.split('/')[1], 0.5*warped_image + 0.5*GT_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "661f0d3b-25bf-4d1a-9ce7-b7bb49a46b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]]),\n",
       " array([ 3.22612168e+00,  1.10804385e+01,  6.14221234e-01,  1.58421183e-01,\n",
       "         2.98708992e+01, -3.41677075e-01, -3.68119014e-06,  2.19233472e-03,\n",
       "         1.00000000e+00]),\n",
       " 'imgs/Wehda-vs-Faisaly-2nd-001969.jpg')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46a9d775-ef73-4e37-974a-d660dab20559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ELU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet_18(nn.Module):\n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ELU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            Block(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def identity_downsample(self, in_channels, out_channels): \n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "881297f7-7daf-41a3-889a-be62329dab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet_18(1, 9)\n",
    "# net.load_state_dict(torch.load('seg-2-cam-pose.model'))\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59f805b5-b61e-4ac6-a6e4-b4887db2d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a7050d19-85b2-44e9-a60f-b784f6608e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94cf3c89-17de-44ba-a851-094ba49b9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    indx = np.random.randint(0, len(data_set))\n",
    "    target_file = data_set[indx][:-4]\n",
    "    # target_file = 'PSG VS Man City 2nd-000367.jpg'\n",
    "    X = cv2.imread(\"GT/{}png\".format(target_file[:-3]), 0)\n",
    "    X[X> 10] = 255\n",
    "    X[X<= 10] = 0\n",
    "    X = X/255.0\n",
    "\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    \n",
    "    X = torch.tensor(X, dtype=torch.float32).cuda()\n",
    "    outputs = net(X)\n",
    "    \n",
    "    M_ = outputs.detach().cpu().numpy()[0]\n",
    "    X = cv2.imread(\"imgs/{}jpg\".format(target_file[:-3]), 0)\n",
    "    print(M_)\n",
    "    M_[2] = M_[2] * X.shape[0]\n",
    "    M_[5] = M_[5] * X.shape[1]\n",
    "    M_[0] = M_[0]/10\n",
    "    M_[1] = M_[1]/10\n",
    "    M_[3] = M_[3]/10\n",
    "    M_[4] = M_[4]/10\n",
    "    \n",
    "    M_ = M_.reshape((3,3))\n",
    "    \n",
    "    print(M_)\n",
    "    \n",
    "    img = cv2.imread(\"imgs/{}jpg\".format(target_file[:-3]))\n",
    "    warped_image = cv2.warpPerspective(img, M_, (GT_img.shape[1], GT_img.shape[0]))\n",
    "    cv2.imwrite('val.jpg', 0.5*warped_image + 0.5*GT_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ba37c-728a-492f-9be4-173e65280284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bd64e-20b2-49b7-bf49-b3ae86c3a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
